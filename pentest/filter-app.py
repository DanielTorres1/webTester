#!/usr/bin/python3
import sys
import re

def process_urls(urls):
    # Lista para almacenar las URLs procesadas
    processed_urls = []

    # Palabras clave para filtrar
    keywords = ['cpanel', 'cpcalendars', 'cpcontacts', 'emails', 'ftp', 'webdisk', 'webmail', 'whm']
    keyword_pattern = re.compile('|'.join(keywords), re.IGNORECASE)

    # Procesar cada URL
    for url in urls:
        url = url.strip()  # Eliminar espacios en blanco alrededor de la URL
        
        # Verificar si la URL contiene alguna de las palabras clave
        if keyword_pattern.search(url):
            continue  # Saltar esta URL si contiene una palabra clave

        if '.' in url.split('/')[-1]:  # Verificar si la URL termina en un archivo
            base_url = '/'.join(url.split('/')[:3]) + '/'  # Extraer la parte base de la URL
        else:
            base_url = url if url.endswith('/') else url + '/'  # Asegurarse de que la URL termine con una barra

        processed_urls.append(base_url)

    # Imprimir las URLs procesadas
    for processed_url in processed_urls:
        print(processed_url)

if __name__ == "__main__":
    urls = sys.stdin.readlines()
    process_urls(urls)